{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入数据\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from model import BiLSTM_CRF\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from train import train, test\n",
    "from metric import f1_score\n",
    "\n",
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 64\n",
    "\n",
    "# 序列字典 \n",
    "tag2id = {\n",
    "    \"O\": 0, \n",
    "    \"B-NAME\": 1, \n",
    "    \"I-NAME\": 2,\n",
    "    \"B-NOTIONAL\": 4, \n",
    "    \"I-NOTIONAL\": 5,\n",
    "    \"B-TICKER\": 6, \n",
    "    \"I-TICKER\": 7,\n",
    "    START_TAG: 8, \n",
    "    STOP_TAG: 9,\n",
    "    '[CLS]': 10,\n",
    "    '[SEP]': 11\n",
    "}\n",
    "\n",
    "def extract(raw_data):\n",
    "    # 改造数据\n",
    "    # BIO Tagging\n",
    "    all_data = []\n",
    "    x = []\n",
    "    y = []\n",
    "    for d in raw_data:\n",
    "        text = d['text'].split()\n",
    "        text = [_t.lower() for _t in text]\n",
    "        sen_label = [] #['o'] * len(text)\n",
    "        labels = d['label']\n",
    "        char_label = ['O'] * len(d['text'])\n",
    "        for la in labels:\n",
    "            start_index = la[1][0]\n",
    "            end_index = la[1][1]\n",
    "            char_label[start_index] = 'B-' + la[0]\n",
    "            for i in range(start_index + 1, end_index):\n",
    "                char_label[i] = 'I-' + la[0]\n",
    "        # print(char_label)\n",
    "        sen_label.append(char_label[0])\n",
    "        for j in range (0,len(d['text'])):\n",
    "            if d['text'][j] == ' ' and j != len(d['text']) - 1 and j != 0:\n",
    "                # print(j)\n",
    "                sen_label.append(char_label[j+1])\n",
    "\n",
    "        x.append(text)\n",
    "        y.append(sen_label)\n",
    "        tri = (text,sen_label)\n",
    "        # print(tri)\n",
    "        all_data.append(tri)\n",
    "\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=0)\n",
    "    x_dev,x_test,y_dev,y_test = train_test_split(x_test,y_test,test_size=0.5,random_state=0)\n",
    "\n",
    "    print(\"x_train is:\"); print(len(x_train))\n",
    "    print(\"y_train is:\"); print(len(y_train))\n",
    "    print(\"x_dev is:\");  print(len(x_test))\n",
    "    print(\"y_dev is:\");  print(len(y_test))\n",
    "    print(\"x_test is:\");  print(len(x_test))\n",
    "    print(\"y_test is:\");  print(len(y_test))\n",
    "    \"\"\"\n",
    "    word_to_ix = {} # 词表\n",
    "    for sentence, tags in all_data:\n",
    "        for word in sentence:\n",
    "            if word not in word_to_ix:\n",
    "                word_to_ix[word] = len(word_to_ix)\n",
    "    \"\"\"\n",
    "    \n",
    "    word_to_ix = {}\n",
    "    for sentence in x_train:\n",
    "        for word in sentence:\n",
    "            if word not in word_to_ix:\n",
    "                word_to_ix[word] = len(word_to_ix)\n",
    "    \n",
    "    np.save('vocab.npy', word_to_ix)\n",
    "    return x_train, y_train, x_dev, y_dev, x_test, y_test, word_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Data load--------\n",
      "cuda\n",
      "x_train is:\n",
      "2100\n",
      "y_train is:\n",
      "2100\n",
      "x_dev is:\n",
      "450\n",
      "y_dev is:\n",
      "450\n",
      "x_test is:\n",
      "450\n",
      "y_test is:\n",
      "450\n",
      "[([0, 1, 2, 3, 4, 5], [0, 1, 2, 0, 4, 6])]\n",
      "-------- Process Done! --------\n",
      "[([26, 27, 3238, 444, 11], [0, 0, 4, 6, 0])]\n",
      "-------- Process Done! --------\n",
      "[([23, 3238, 929, 6], [0, 4, 6, 0])]\n",
      "-------- Process Done! --------\n"
     ]
    }
   ],
   "source": [
    "from data_loader import NERDataset\n",
    "\n",
    "f = open('data.json') \n",
    "# 数据部分\n",
    "data = json.load(f)\n",
    "print('--------Data load--------')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "\n",
    "print(device)\n",
    "x_train, y_train, x_dev, y_dev, x_test, y_test, word2id = extract(data)\n",
    "\n",
    "unk_id = len(word2id)\n",
    "print(unk_id)\n",
    "word2id['<unk1>'] = unk_id # 未知词\n",
    "\n",
    "train_dataset = NERDataset(x_train, y_train, word2id, tag2id, unk_id)\n",
    "dev_dataset = NERDataset(x_dev, y_dev, word2id, tag2id, unk_id)\n",
    "test_dataset = NERDataset(x_test, y_test, word2id, tag2id, unk_id)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32,\n",
    "                            shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=32,\n",
    "                            shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32,\n",
    "                        shuffle=True, collate_fn=test_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------model define--------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BiLSTM_CRF(\n",
       "  (embedding): Embedding(3239, 128)\n",
       "  (lstm): LSTM(128, 32, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (hidden2tag): Linear(in_features=64, out_features=11, bias=True)\n",
       "  (crf): CRF(num_tags=11)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1' # 下面老是报错 shape 不一致\n",
    "\n",
    "model = BiLSTM_CRF(\n",
    "    embedding_dim = EMBEDDING_DIM, # 128\n",
    "    hidden_dim = HIDDEN_DIM, # 64\n",
    "    vocab_size = len(word2id),\n",
    "    tag_to_ix = tag2id \n",
    ")\n",
    "\n",
    "print(\"--------model define--------\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/66 [00:00<?, ?it/s]d:\\Anaconda_install\\envs\\myenv\\lib\\site-packages\\torchcrf\\__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorCompare.cpp:402.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n",
      "100%|██████████| 66/66 [00:03<00:00, 18.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train loss: 66.59553400675456\n",
      "epoch: 1, f1 score: 0.9621621621621622, dev loss: 10.199355061848959\n",
      "--------Save best model!--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:04<00:00, 14.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, train loss: 9.225349368471088\n",
      "epoch: 2, f1 score: 0.994059405940594, dev loss: 4.851529947916666\n",
      "--------Save best model!--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:04<00:00, 15.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, train loss: 5.7612910559683135\n",
      "epoch: 3, f1 score: 0.9955467590301831, dev loss: 4.149214426676433\n",
      "--------Save best model!--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:04<00:00, 15.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, train loss: 4.302227540449663\n",
      "epoch: 4, f1 score: 0.9965363681345869, dev loss: 3.356384023030599\n",
      "--------Save best model!--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:04<00:00, 14.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, train loss: 3.7093129591508345\n",
      "epoch: 5, f1 score: 0.9965363681345869, dev loss: 3.1289708455403646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:04<00:00, 14.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, train loss: 3.053154974272757\n",
      "epoch: 6, f1 score: 0.9965363681345869, dev loss: 3.2501347859700522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:04<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, train loss: 2.561188567768444\n",
      "epoch: 7, f1 score: 0.9930555555555556, dev loss: 3.6088437398274738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:04<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, train loss: 2.08862879782012\n",
      "epoch: 8, f1 score: 0.9965363681345869, dev loss: 2.5972941080729166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:04<00:00, 15.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, train loss: 1.7705114538019353\n",
      "epoch: 9, f1 score: 0.9965363681345869, dev loss: 2.715096028645833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:04<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, train loss: 1.5808453704371597\n",
      "epoch: 10, f1 score: 0.9965363681345869, dev loss: 2.50779291788737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:04<00:00, 15.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11, train loss: 1.3388647310661548\n",
      "epoch: 11, f1 score: 0.9890329012961117, dev loss: 3.676182810465495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:04<00:00, 15.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12, train loss: 1.2056514855587122\n",
      "epoch: 12, f1 score: 0.994047619047619, dev loss: 2.8602032979329426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:04<00:00, 15.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13, train loss: 0.9682432376977169\n",
      "epoch: 13, f1 score: 0.9950445986124876, dev loss: 2.734649149576823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:04<00:00, 14.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14, train loss: 0.9008352539756082\n",
      "epoch: 14, f1 score: 0.9910447761194029, dev loss: 3.0294520060221353\n",
      "Best val f1: 0.9965363681345869\n",
      "Training Finished!\n",
      "--------train over--------\n"
     ]
    }
   ],
   "source": [
    "train(train_loader, dev_loader, word2id, tag2id, model, optimizer, device, scheduler )\n",
    "print(\"--------train over--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终测试集f1分数： 0.9955686853766617\n",
      "各标签识别情况\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NAME</td>\n",
       "      <td>0.995816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOTIONAL</td>\n",
       "      <td>0.992161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TICKER</td>\n",
       "      <td>0.998888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  f1_score\n",
       "0      NAME  0.995816\n",
       "1  NOTIONAL  0.992161\n",
       "2    TICKER  0.998888"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results = test(test_loader, word2id, tag2id, model, device)\n",
    "df = pd.DataFrame.from_dict(results['f1_labels'], orient='index',columns=['f1_score'])\n",
    "df = df.reset_index().rename(columns = {'index':'label'})\n",
    "\n",
    "print('最终测试集f1分数： {}'.format(results['f1']))\n",
    "print(\"各标签识别情况\")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73245adb4c9b89cfab2aa0cee6d43d4d2a1167f1fee74fb80cf80052206c4483"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
